{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from src.utils.generative import Generator\n",
    "from src.utils.tokenizer import Tokenizer\n",
    "from src.utils.embedding import Embedding\n",
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_columns', 10000)  # or 1000\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('data/the-reddit-dataset-dataset-comments.csv')[['permalink','body']]\n",
    "posts = pd.read_csv('data/the-reddit-dataset-dataset-posts.csv')[['permalink','selftext','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.dropna(inplace=True)\n",
    "posts.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['post_id'] = comments['permalink'].apply(lambda x: extract_post_id(x))\n",
    "posts['post_id'] = posts['permalink'].apply(lambda x: extract_post_id(x))\n",
    "comments['true_label'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in comments.iterrows():\n",
    "    choice = np.random.choice([False, True], p=[0.1, 0.9])\n",
    "    if not choice:  # 10% probability\n",
    "        # Choose a random row from the DataFrame\n",
    "        random_row = comments.sample()\n",
    "        # Replace the ID of the current row with the ID of the random row\n",
    "        comments.at[i, 'post_id'] = random_row['post_id'].values[0]\n",
    "    comments.at[i, 'true_label'] = choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# # Tokenize the dataset\n",
    "print('Tokenizing sentences')\n",
    "posts['tokenized_conclusion'] = posts['title'].apply(lambda x: tokenizer(x))\n",
    "posts['tokenized_premisse'] = posts['selftext'].apply(lambda x: tokenizer(x))\n",
    "comments['tokenized_text'] = comments['body'].apply(lambda x: tokenizer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(posts,comments,how='right',on='post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word representation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an Embedding object\n",
    "embedding = Embedding()\n",
    "print('Creating word representation')\n",
    "# # Perform the embeddings\n",
    "merged_df['wc'] = merged_df.apply(lambda row: calc_word_sim(row['tokenized_conclusion'],row['tokenized_text'],embedding),axis=1)\n",
    "merged_df['wp'] = merged_df.apply(lambda row: calc_word_sim(row['tokenized_premisse'],row['tokenized_text'],embedding),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permalink_x</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>tokenized_conclusion</th>\n",
       "      <th>tokenized_premisse</th>\n",
       "      <th>permalink_y</th>\n",
       "      <th>body</th>\n",
       "      <th>true_label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>wc</th>\n",
       "      <th>wp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t45...</td>\n",
       "      <td>I’m looking for a dataset that I can use to id...</td>\n",
       "      <td>[request] looking for a dataset that i can use...</td>\n",
       "      <td>t45uk7</td>\n",
       "      <td>[[, request, ], look, for, a, dataset, that, i...</td>\n",
       "      <td>[i, ’, m, look, for, a, dataset, that, i, can,...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t45...</td>\n",
       "      <td>Spatial problem: Suitability of new locations ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[spatial, problem, :, suitabl, of, new, locat,...</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/sg9...</td>\n",
       "      <td>I collected news articles over the past 2 year...</td>\n",
       "      <td>Brainstorm some ideas with me for this Article...</td>\n",
       "      <td>sg9lv8</td>\n",
       "      <td>[brainstorm, some, idea, with, me, for, thi, a...</td>\n",
       "      <td>[i, collect, news, articl, over, the, past, 2,...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/sg9...</td>\n",
       "      <td>Have you tried toying around with GDELT or Ali...</td>\n",
       "      <td>True</td>\n",
       "      <td>[have, you, tri, toy, around, with, gdelt, or,...</td>\n",
       "      <td>19</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t49...</td>\n",
       "      <td>Hi, I have a dataset with countries by 3 lette...</td>\n",
       "      <td>3 letter country code to full country name</td>\n",
       "      <td>t49fq0</td>\n",
       "      <td>[3, letter, countri, code, to, full, countri, ...</td>\n",
       "      <td>[hi, ,, i, have, a, dataset, with, countri, by...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t49...</td>\n",
       "      <td>I was about to write and say this shouldn't be...</td>\n",
       "      <td>True</td>\n",
       "      <td>[i, wa, about, to, write, and, say, thi, shoul...</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t47...</td>\n",
       "      <td>I want to classify if an image contains a cont...</td>\n",
       "      <td>Looking for datasets that contain images of co...</td>\n",
       "      <td>t47wiw</td>\n",
       "      <td>[look, for, dataset, that, contain, imag, of, ...</td>\n",
       "      <td>[i, want, to, classifi, if, an, imag, contain,...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t47...</td>\n",
       "      <td>I'm not exactly sure how many contracts the E...</td>\n",
       "      <td>True</td>\n",
       "      <td>[i, 'm, not, exactli, sure, how, mani, contrac...</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t49...</td>\n",
       "      <td>Hi, I have a dataset with countries by 3 lette...</td>\n",
       "      <td>3 letter country code to full country name</td>\n",
       "      <td>t49fq0</td>\n",
       "      <td>[3, letter, countri, code, to, full, countri, ...</td>\n",
       "      <td>[hi, ,, i, have, a, dataset, with, countri, by...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/t49...</td>\n",
       "      <td>nevermind, found it\\n\\nfor anyone in need:\\n\\n...</td>\n",
       "      <td>True</td>\n",
       "      <td>[nevermind, ,, found, it, for, anyon, in, need...</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54819</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/3bx...</td>\n",
       "      <td>I am currently doing a massive analysis of Red...</td>\n",
       "      <td>I have every publicly available Reddit comment...</td>\n",
       "      <td>3bxlg7</td>\n",
       "      <td>[i, have, everi, publicli, avail, reddit, comm...</td>\n",
       "      <td>[i, am, current, do, a, massiv, analysi, of, r...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bn9...</td>\n",
       "      <td>If you divide population by CO2, you get some ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[if, you, divid, popul, by, co2, ,, you, get, ...</td>\n",
       "      <td>70</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54835</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>Doesn't need to be anything fancy: list of cit...</td>\n",
       "      <td>Ask /r/datasets: good resource for city/town a...</td>\n",
       "      <td>bmn4z</td>\n",
       "      <td>[ask, /r/dataset, :, good, resourc, for, city/...</td>\n",
       "      <td>[doe, n't, need, to, be, anyth, fanci, :, list...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>True</td>\n",
       "      <td>[[, delet, ]]</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54838</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>Doesn't need to be anything fancy: list of cit...</td>\n",
       "      <td>Ask /r/datasets: good resource for city/town a...</td>\n",
       "      <td>bmn4z</td>\n",
       "      <td>[ask, /r/dataset, :, good, resourc, for, city/...</td>\n",
       "      <td>[doe, n't, need, to, be, anyth, fanci, :, list...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>I found this that's turned out to be a great r...</td>\n",
       "      <td>True</td>\n",
       "      <td>[i, found, thi, that, 's, turn, out, to, be, a...</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54840</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>Doesn't need to be anything fancy: list of cit...</td>\n",
       "      <td>Ask /r/datasets: good resource for city/town a...</td>\n",
       "      <td>bmn4z</td>\n",
       "      <td>[ask, /r/dataset, :, good, resourc, for, city/...</td>\n",
       "      <td>[doe, n't, need, to, be, anyth, fanci, :, list...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmn...</td>\n",
       "      <td>This was posted in another thread.\\r\\n\\r\\nhttp...</td>\n",
       "      <td>True</td>\n",
       "      <td>[thi, wa, post, in, anoth, thread, ., http, :,...</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54845</th>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmj...</td>\n",
       "      <td>[YQL](http://developer.yahoo.com/yql/)\\n\\nPROT...</td>\n",
       "      <td>Real-Time Access to a lot of datasets through ...</td>\n",
       "      <td>bmjvh</td>\n",
       "      <td>[real-tim, access, to, a, lot, of, dataset, th...</td>\n",
       "      <td>[[, yql, ], (, http, :, //developer.yahoo.com/...</td>\n",
       "      <td>https://old.reddit.com/r/datasets/comments/bmj...</td>\n",
       "      <td>https://developer.yahoo.com/yql/console/?q=SEL...</td>\n",
       "      <td>True</td>\n",
       "      <td>[http, :, //developer.yahoo.com/yql/console/, ...</td>\n",
       "      <td>129</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44882 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             permalink_x  \\\n",
       "0      https://old.reddit.com/r/datasets/comments/t45...   \n",
       "1      https://old.reddit.com/r/datasets/comments/sg9...   \n",
       "4      https://old.reddit.com/r/datasets/comments/t49...   \n",
       "5      https://old.reddit.com/r/datasets/comments/t47...   \n",
       "6      https://old.reddit.com/r/datasets/comments/t49...   \n",
       "...                                                  ...   \n",
       "54819  https://old.reddit.com/r/datasets/comments/3bx...   \n",
       "54835  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54838  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54840  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54845  https://old.reddit.com/r/datasets/comments/bmj...   \n",
       "\n",
       "                                                selftext  \\\n",
       "0      I’m looking for a dataset that I can use to id...   \n",
       "1      I collected news articles over the past 2 year...   \n",
       "4      Hi, I have a dataset with countries by 3 lette...   \n",
       "5      I want to classify if an image contains a cont...   \n",
       "6      Hi, I have a dataset with countries by 3 lette...   \n",
       "...                                                  ...   \n",
       "54819  I am currently doing a massive analysis of Red...   \n",
       "54835  Doesn't need to be anything fancy: list of cit...   \n",
       "54838  Doesn't need to be anything fancy: list of cit...   \n",
       "54840  Doesn't need to be anything fancy: list of cit...   \n",
       "54845  [YQL](http://developer.yahoo.com/yql/)\\n\\nPROT...   \n",
       "\n",
       "                                                   title post_id  \\\n",
       "0      [request] looking for a dataset that i can use...  t45uk7   \n",
       "1      Brainstorm some ideas with me for this Article...  sg9lv8   \n",
       "4             3 letter country code to full country name  t49fq0   \n",
       "5      Looking for datasets that contain images of co...  t47wiw   \n",
       "6             3 letter country code to full country name  t49fq0   \n",
       "...                                                  ...     ...   \n",
       "54819  I have every publicly available Reddit comment...  3bxlg7   \n",
       "54835  Ask /r/datasets: good resource for city/town a...   bmn4z   \n",
       "54838  Ask /r/datasets: good resource for city/town a...   bmn4z   \n",
       "54840  Ask /r/datasets: good resource for city/town a...   bmn4z   \n",
       "54845  Real-Time Access to a lot of datasets through ...   bmjvh   \n",
       "\n",
       "                                    tokenized_conclusion  \\\n",
       "0      [[, request, ], look, for, a, dataset, that, i...   \n",
       "1      [brainstorm, some, idea, with, me, for, thi, a...   \n",
       "4      [3, letter, countri, code, to, full, countri, ...   \n",
       "5      [look, for, dataset, that, contain, imag, of, ...   \n",
       "6      [3, letter, countri, code, to, full, countri, ...   \n",
       "...                                                  ...   \n",
       "54819  [i, have, everi, publicli, avail, reddit, comm...   \n",
       "54835  [ask, /r/dataset, :, good, resourc, for, city/...   \n",
       "54838  [ask, /r/dataset, :, good, resourc, for, city/...   \n",
       "54840  [ask, /r/dataset, :, good, resourc, for, city/...   \n",
       "54845  [real-tim, access, to, a, lot, of, dataset, th...   \n",
       "\n",
       "                                      tokenized_premisse  \\\n",
       "0      [i, ’, m, look, for, a, dataset, that, i, can,...   \n",
       "1      [i, collect, news, articl, over, the, past, 2,...   \n",
       "4      [hi, ,, i, have, a, dataset, with, countri, by...   \n",
       "5      [i, want, to, classifi, if, an, imag, contain,...   \n",
       "6      [hi, ,, i, have, a, dataset, with, countri, by...   \n",
       "...                                                  ...   \n",
       "54819  [i, am, current, do, a, massiv, analysi, of, r...   \n",
       "54835  [doe, n't, need, to, be, anyth, fanci, :, list...   \n",
       "54838  [doe, n't, need, to, be, anyth, fanci, :, list...   \n",
       "54840  [doe, n't, need, to, be, anyth, fanci, :, list...   \n",
       "54845  [[, yql, ], (, http, :, //developer.yahoo.com/...   \n",
       "\n",
       "                                             permalink_y  \\\n",
       "0      https://old.reddit.com/r/datasets/comments/t45...   \n",
       "1      https://old.reddit.com/r/datasets/comments/sg9...   \n",
       "4      https://old.reddit.com/r/datasets/comments/t49...   \n",
       "5      https://old.reddit.com/r/datasets/comments/t47...   \n",
       "6      https://old.reddit.com/r/datasets/comments/t49...   \n",
       "...                                                  ...   \n",
       "54819  https://old.reddit.com/r/datasets/comments/bn9...   \n",
       "54835  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54838  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54840  https://old.reddit.com/r/datasets/comments/bmn...   \n",
       "54845  https://old.reddit.com/r/datasets/comments/bmj...   \n",
       "\n",
       "                                                    body  true_label  \\\n",
       "0      Spatial problem: Suitability of new locations ...        True   \n",
       "1      Have you tried toying around with GDELT or Ali...        True   \n",
       "4      I was about to write and say this shouldn't be...        True   \n",
       "5       I'm not exactly sure how many contracts the E...        True   \n",
       "6      nevermind, found it\\n\\nfor anyone in need:\\n\\n...        True   \n",
       "...                                                  ...         ...   \n",
       "54819  If you divide population by CO2, you get some ...       False   \n",
       "54835                                          [deleted]        True   \n",
       "54838  I found this that's turned out to be a great r...        True   \n",
       "54840  This was posted in another thread.\\r\\n\\r\\nhttp...        True   \n",
       "54845  https://developer.yahoo.com/yql/console/?q=SEL...        True   \n",
       "\n",
       "                                          tokenized_text   wc    wp  \n",
       "0      [spatial, problem, :, suitabl, of, new, locat,...   30    43  \n",
       "1      [have, you, tri, toy, around, with, gdelt, or,...   19   459  \n",
       "4      [i, wa, about, to, write, and, say, thi, shoul...   30    53  \n",
       "5      [i, 'm, not, exactli, sure, how, mani, contrac...   56    65  \n",
       "6      [nevermind, ,, found, it, for, anyon, in, need...   20    47  \n",
       "...                                                  ...  ...   ...  \n",
       "54819  [if, you, divid, popul, by, co2, ,, you, get, ...   70  1163  \n",
       "54835                                      [[, delet, ]]   16    47  \n",
       "54838  [i, found, thi, that, 's, turn, out, to, be, a...   31    50  \n",
       "54840  [thi, wa, post, in, anoth, thread, ., http, :,...   21    48  \n",
       "54845  [http, :, //developer.yahoo.com/yql/console/, ...  129   122  \n",
       "\n",
       "[44882 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding representation\n"
     ]
    }
   ],
   "source": [
    "print('Creating embedding representation')\n",
    "# # Perform the embeddings\n",
    "merged_df['ec'] = merged_df.apply(lambda row: compute_wmd(row['tokenized_conclusion'],row['tokenized_text'],embedding.model),axis=1)\n",
    "merged_df['ep'] = merged_df.apply(lambda row: compute_wmd(row['tokenized_premisse'],row['tokenized_text'],embedding.model),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding representation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FACULDADE\\RECUPERAÇÂO DA INF. 2023.2\\TrabFinal\\src\\utils\\utils.py:131: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return alpha*(w_plus + e_plus) - (1-alpha)*(w_up+e_up)\n",
      "d:\\FACULDADE\\RECUPERAÇÂO DA INF. 2023.2\\TrabFinal\\src\\utils\\utils.py:131: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return alpha*(w_plus + e_plus) - (1-alpha)*(w_up+e_up)\n"
     ]
    }
   ],
   "source": [
    "print('Creating embedding representation')\n",
    "# # Perform the embeddings\n",
    "merged_df['fmodel'] = merged_df.apply(lambda row: calc_sim_dissim(row['wc'],row['wp'],row['ec'],row['ep']),axis=1)\n",
    "merged_df['fmodel'] = merged_df.apply(lambda row: calc_sim_dissim(row['wc'],row['wp'],row['ec'],row['ep']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-test para diferença de médias H_0 = Médias Iguais \n",
      " p-value: 0.027114685900800076\n"
     ]
    }
   ],
   "source": [
    "t_test_for_mean = compute_t_test(merged_df[merged_df['true_label']]['fmodel'],merged_df[~merged_df['true_label']]['fmodel'])\n",
    "print('T-test para diferença de médias H_0 = Médias Iguais \\n p-value:',t_test_for_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
